{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **MNIST Classification**"
      ],
      "metadata": {
        "id": "c6bCVJmDs9CF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In the dynamic domain of machine learning, algorithms serve as instrumental instruments for extracting meaningful insights from data. This report meticulously examines the implementation and analysis of two pivotal algorithmsâ€”linear regression and softmax regression.\n",
        "\n",
        "While linear regression adeptly models relationships between variables, softmax regression serves as an extension of logistic regression, offering a specialized methodology for managing multiclass classification tasks.\n",
        "\n",
        "Both algorithms are foundational within the realm of supervised learning, possessing unique attributes that contribute to their respective strengths. This exploration aims to elucidate the intricacies of these algorithms, delineating their applications, strengths, and limitations, thereby facilitating a comprehensive understanding of their effieciency in guiding data-driven decision-making.\n"
      ],
      "metadata": {
        "id": "zdinvhCHxWi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preparations**"
      ],
      "metadata": {
        "id": "bQgVaejqtx2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this segment, the MNIST dataset is going to be loaded, divided, and prepared for use.\n",
        "\n",
        "The original dataset comprises 70,000 grayscale images, each measuring 28x28 pixels, representing handwritten digits.\n",
        "\n",
        "Upon retrieval, the dataset will be partitioned into a training set (consisting of 60,000 images along with their respective labels) and a test set (comprising 10,000 images along with their labels).\n",
        "\n",
        "During preprocessing, the images will be flattened into 1-dimensional vectors, converting each from 28x28 (784 pixels in total) to a single vector, and normalized to the range 0-1.\n",
        "\n",
        "To implement the bias trick, an additional entry will be appended to every vector within the dataset, resulting in vectors of length 785:\n",
        "\n",
        "X_train: 60,000 x 785\n",
        "Y_train: 60,000 x 10\n",
        "X_test: 10,000 x 785\n",
        "Y_test: 10,000 x 10"
      ],
      "metadata": {
        "id": "GV7fz-wkt4fO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuUuc3VWdnUz"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch MNIST dataset, and unpack it to images (X) and labels (Y)\n",
        "def set_data():\n",
        "\n",
        "    # Import data\n",
        "    mnist = fetch_openml('mnist_784', version=1)\n",
        "\n",
        "    # Extract Images and labels\n",
        "    X = mnist['data'].values\n",
        "    Y = mnist['target'].to_numpy(dtype=int)\n",
        "\n",
        "    # Normalize data\n",
        "    X /= 255.0\n",
        "\n",
        "    # Add ones vector to implement the 'bias trick'\n",
        "    X = np.column_stack([np.ones(X.shape[0]), X])\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7uip-nCSfSr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch data and split it into train and test data\n",
        "X_all, Y_all = set_data()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_all, Y_all, test_size=10000)"
      ],
      "metadata": {
        "id": "pXcgPBClkXs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22efd07-9e88-4e65-9fea-75074f5fea99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Softmax Regression**"
      ],
      "metadata": {
        "id": "IE_rRBl6z-c2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In my implementation for softmax regression on the MNIST dataset on this section, the cornerstone lies in leveraging gradient descent and cross-entropy loss to facilitate effective multi-class classification.\n",
        "The model utilizes the softmax function to transform raw output scores (W.T*X) into probability distributions across the digit classes.\n",
        "During the training phase, the cross-entropy loss serves as a crucial metric to quantify the disparity between predicted probabilities and actual class labels. Employing gradient descent as the optimization strategy, the algorithm iteratively refines model parameters to minimize this loss, thereby enhancing the overall classification accuracy."
      ],
      "metadata": {
        "id": "tg_FfSDVcWWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Y_train - 60000X1\n",
        "# X_train - 60000X785\n",
        "# W - 785X10\n",
        "\n",
        "# Implement the softmax function\n",
        "def softmax(scores):\n",
        "    exp_scores = np.exp(scores)\n",
        "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "# Implement the cross entropy loss\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    return -np.sum(y_true * np.log(y_pred)) / len(y_true)\n",
        "\n",
        "# Predict labels based on calculated weights using softmax function\n",
        "def predict(X, W):\n",
        "        scores = np.dot(X, W)\n",
        "        y_pred = softmax(scores)\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "# Implement the gradient descent algorithm on the softmax function\n",
        "def gradient_descent(X_train, Y_train, X_test, Y_test, learning_rate=1, epochs=100, W = None, epsilon = 0.1):\n",
        "    num_samples, num_classes = X_train.shape[0], Y_train.shape[1]\n",
        "\n",
        "    if W is None:\n",
        "      # Initialize weights to random values\n",
        "      W = np.random.randn(X_train.shape[1], num_classes)\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Predict\n",
        "        y_pred_train = predict(X_train, W)\n",
        "        y_pred_test = predict(X_test, W)\n",
        "\n",
        "        # Compute losses\n",
        "        train_loss = cross_entropy_loss(Y_train, y_pred_train)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        test_loss = cross_entropy_loss(Y_test, y_pred_test)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        # calculate gradient and the correction factor dW\n",
        "        gradient = (y_pred_train - Y_train) / num_samples\n",
        "        dW = np.dot(X_train.T, gradient)\n",
        "\n",
        "        # Update weights\n",
        "        W -= learning_rate * dW\n",
        "\n",
        "        if train_loss < epsilon:\n",
        "          break\n",
        "\n",
        "    return W, train_losses, test_losses"
      ],
      "metadata": {
        "id": "mCdyJsOnN--E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters and constants\n",
        "num_classes = 10\n",
        "num_features = X_train.shape[1]\n",
        "num_epochs = 600\n",
        "lr = 1\n",
        "\n",
        "# Transform Y_train and Y_test to one hot\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "Y_train_oh = encoder.fit_transform(Y_train.reshape(-1, 1))\n",
        "Y_test_oh = encoder.fit_transform(Y_test.reshape(-1, 1))\n",
        "\n",
        "\n",
        "# Train the model using gradient descent to find optimal weights\n",
        "W_optimal, train_losses, test_losses = gradient_descent(X_train, Y_train_oh, X_test, Y_test_oh, epochs=num_epochs\n",
        "                             ,learning_rate=lr)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RyxFn7eQPYt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b639561e-f845-407c-c771-19f88abfeede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Results**"
      ],
      "metadata": {
        "id": "oEp0O0TUfjgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_results_softmax_regression(X, W ,Y):\n",
        "  # Predict scores\n",
        "  y_pred_scores = predict(X, W)\n",
        "\n",
        "  # predicted label is the one with largest score\n",
        "  y_pred_labels = np.argmax(y_pred_scores, axis=1)\n",
        "\n",
        "  # Accuracy = num of correct predictions / num of total predictions\n",
        "  acc = np.sum(y_pred_labels == Y) / Y.shape[0]\n",
        "\n",
        "  print (\"ACC for multi-class clasification using softmax regression = \" + str(acc))\n",
        "\n",
        "  # Calculate confusion matrix for the multi-class model\n",
        "  conf_matrix = confusion_matrix(Y, y_pred_labels)\n",
        "  print (\"\\nConfusion matrix for the multi-class clasification using softmax regression:\")\n",
        "  print (conf_matrix)\n",
        "\n",
        "\n",
        "  # Calculate TPR for each digit\n",
        "  tpr_per_class = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)\n",
        "  print(\"\\nTrue Positive Rate (TPR) for Each digit:\")\n",
        "  for i, tpr in enumerate(tpr_per_class):\n",
        "      print(f\"digit {i}: TPR = {tpr:.4f}\")\n",
        "\n",
        "\n",
        "  unique_classes = np.arange(W.shape[1])\n",
        "  # Iterate through each class and compute the confusion matrix\n",
        "  for class_label in unique_classes:\n",
        "      class_y_true = (Y == class_label).astype(int)\n",
        "      class_y_pred = (y_pred_labels == class_label).astype(int)\n",
        "\n",
        "      conf_matrix_class = confusion_matrix(class_y_true, class_y_pred)\n",
        "\n",
        "      # Calculate ACC for each digit using the confusion matrix\n",
        "      TP = conf_matrix_class[0,0]\n",
        "      TN = conf_matrix_class[1,1]\n",
        "\n",
        "      acc = 100*(TP+TN)/np.sum(conf_matrix_class)\n",
        "      print(f\"\\nAccuracy for digit {class_label}: {acc}%\")\n",
        "\n",
        "      # Print the confusion matrix for the current class\n",
        "      print(f\"Confusion Matrix for digit {class_label}:\\n{conf_matrix_class}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_losses(train_losses, test_losses):\n",
        "    plt.clf()\n",
        "    plt.title(\"Loss for softmax regression VS epoch\")\n",
        "    plt.xlabel(\"Epoch number\")\n",
        "    plt.ylabel(\"Cross Entropy Loss\")\n",
        "    plt.plot(range(1, len(train_losses) + 1), train_losses, label=\"train loss\")\n",
        "    plt.plot(range(1, len(test_losses) + 1), test_losses, label=\"test loss\")\n",
        "    plt.legend(['Train loss', 'Test loss'])\n",
        "    # plt.savefig(\"perceptron \" + str(self.digit) + \"  loss\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ak_bzEHvSHNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Results for softmax regression:\")\n",
        "plot_losses(train_losses, test_losses)\n",
        "show_results_softmax_regression(X_test, W_optimal ,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sl-VbtMYfi4F",
        "outputId": "ab7074c4-6d1c-4c9c-ab7a-cce98e8dbfd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for softmax regression:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACC for multi-class clasification using softmax regression = 0.8804\n",
            "\n",
            "Confusion matrix for the multi-class clasification using softmax regression:\n",
            "[[ 885    0    8    1    2   20    9    2   15    1]\n",
            " [   0 1068    3    5    4    4    4    5   28    2]\n",
            " [  10   10  885   19   20    7   19   14   41    7]\n",
            " [   4    7   34  862    4   41    9   20   21   12]\n",
            " [   4    9    9    1  862    3    9   10   10   43]\n",
            " [  13    4   12   43   11  775   18   10   44   13]\n",
            " [  10    3   27    2   11   19  938    3    6    0]\n",
            " [   2    5   17    7   12    2    0  945    6   37]\n",
            " [   5   20   18   41    7   52   10    7  799   22]\n",
            " [  16    5    4   12   65    3    1   44   17  785]]\n",
            "\n",
            "True Positive Rate (TPR) for Each digit:\n",
            "digit 0: TPR = 0.9326\n",
            "digit 1: TPR = 0.9443\n",
            "digit 2: TPR = 0.8702\n",
            "digit 3: TPR = 0.8681\n",
            "digit 4: TPR = 0.8637\n",
            "digit 5: TPR = 0.8369\n",
            "digit 6: TPR = 0.9223\n",
            "digit 7: TPR = 0.8915\n",
            "digit 8: TPR = 0.8095\n",
            "digit 9: TPR = 0.8514\n",
            "\n",
            "Accuracy for digit 0: 98.78%\n",
            "Confusion Matrix for digit 0:\n",
            "[[8993   64]\n",
            " [  58  885]]\n",
            "\n",
            "Accuracy for digit 1: 98.82%\n",
            "Confusion Matrix for digit 1:\n",
            "[[8814   63]\n",
            " [  55 1068]]\n",
            "\n",
            "Accuracy for digit 2: 97.21%\n",
            "Confusion Matrix for digit 2:\n",
            "[[8836  132]\n",
            " [ 147  885]]\n",
            "\n",
            "Accuracy for digit 3: 97.17%\n",
            "Confusion Matrix for digit 3:\n",
            "[[8855  131]\n",
            " [ 152  862]]\n",
            "\n",
            "Accuracy for digit 4: 97.66%\n",
            "Confusion Matrix for digit 4:\n",
            "[[8904  136]\n",
            " [  98  862]]\n",
            "\n",
            "Accuracy for digit 5: 96.81%\n",
            "Confusion Matrix for digit 5:\n",
            "[[8906  151]\n",
            " [ 168  775]]\n",
            "\n",
            "Accuracy for digit 6: 98.4%\n",
            "Confusion Matrix for digit 6:\n",
            "[[8902   79]\n",
            " [  81  938]]\n",
            "\n",
            "Accuracy for digit 7: 97.97%\n",
            "Confusion Matrix for digit 7:\n",
            "[[8852  115]\n",
            " [  88  945]]\n",
            "\n",
            "Accuracy for digit 8: 96.3%\n",
            "Confusion Matrix for digit 8:\n",
            "[[8831  188]\n",
            " [ 182  799]]\n",
            "\n",
            "Accuracy for digit 9: 96.96%\n",
            "Confusion Matrix for digit 9:\n",
            "[[8911  137]\n",
            " [ 167  785]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Discussion**"
      ],
      "metadata": {
        "id": "YkQaaOXphWH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The overall accuracy achieved for the multi-class classification using gradient descent with softmax regression is 87.79%, indicating a robust performance in distinguishing between the ten digits. The confusion matrix provides a detailed breakdown of the model's predictions for each class.\n",
        "\n",
        "Upon closer inspection of the confusion matrix, it is evident that the model performs exceptionally well in correctly classifying digits 0, 1, and 6, with accuracies exceeding 98%. Digits 2, 4, and 7 also demonstrate high accuracies, hovering around 97-98%. However, the model faces relatively more challenges with digits 5, 8, and 9, where accuracies drop slightly to the mid-90s. These discrepancies may stem from the inherent complexities in distinguishing visually similar digits.\n",
        "\n",
        "Analyzing the true positive rates (TPR) for each digit further emphasizes the model's strengths and weaknesses. Notably, digits 0 and 1 exhibit TPRs above 93%, reinforcing the model's proficiency in correctly identifying these digits. On the other hand, digits 5 and 8 display lower TPRs, indicating areas where the model may benefit from further refinement.\n"
      ],
      "metadata": {
        "id": "eeiswEoaP28-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Linear Regression**\n"
      ],
      "metadata": {
        "id": "pIyoZsUd3Eqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression, a foundational algorithm in machine learning, is conventionally associated with regression tasks; however, its adaptability extends beyond predicting continuous values.\n",
        "In the context of the multi-class classification, the application of linear regression on the MNIST dataset may seem unconventional yet offers an insightful perspective."
      ],
      "metadata": {
        "id": "bKre8sLde08O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a formal context, when presented with input images represented by X and their corresponding labels denoted as y, the least squares solution is expressed as W = (X^T * X)^-1 * X^T * y.\n",
        "Subsequently, for a novel input image X_t, the anticipated scores for each class are determined through the equation y_pred = X_t * W.\n",
        "Notably, the values within y_pred are continuous, not restricted to integers. To finalize predictions for each image, the argmax function is applied to the vector of predictions associated with each image."
      ],
      "metadata": {
        "id": "0GYGFAOviCST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def least_squares(X, y):\n",
        "\n",
        "    # Calculate the least squares solution\n",
        "    Weights = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)\n",
        "\n",
        "    return Weights\n",
        "\n",
        "def linear_regression_predict(X, Weights):\n",
        "\n",
        "    # Predict labels using the learned weights\n",
        "    y_pred = X.dot(Weights)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PnppnC8M3CYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mse(Y, y_pred):\n",
        "\n",
        "  # Calculate MSE for two vectors\n",
        "  mse = np.mean((Y - y_pred) ** 2)\n",
        "  return mse\n",
        "\n",
        "\n",
        "def calculate_acc(Y, y_pred):\n",
        "\n",
        "  # Calculate Accuracy for two one hot encoded vectors\n",
        "  acc = 100 * np.sum(np.all(Y == y_pred, axis=1)) / Y.shape[0]\n",
        "  return acc\n",
        "\n",
        "def show_results_linear_regression(X_train, Y_train_oh, X_test, Y_test_oh):\n",
        "\n",
        "  # Finf optimal weights using least squares\n",
        "  W = least_squares(X_train, Y_train_oh)\n",
        "\n",
        "  # Predict labels on test set\n",
        "  y_pred = linear_regression_predict(X_test, W)\n",
        "\n",
        "  # Transofrm prediction one hot to match predictions\n",
        "  y_pred_one_hot = np.zeros_like(y_pred)\n",
        "  y_pred_one_hot[np.arange(len(y_pred)), y_pred.argmax(axis=1)] = 1\n",
        "\n",
        "\n",
        "  mse = calculate_mse(Y_test_oh, y_pred_one_hot)\n",
        "  acc = calculate_acc(Y_test_oh, y_pred_one_hot)\n",
        "  print(f\"\\nIn-Sample Erorr (MSE) for linear regresson: {mse}\")\n",
        "  print (f\"ACC for multi-class clasification using linear regression = {acc}%\")\n",
        "\n",
        "\n",
        "\n",
        "  # Calculate confusion matrix\n",
        "  Y = np.argmax(Y_test_oh, axis=1)\n",
        "  y_pred_labels = np.argmax(y_pred_one_hot, axis=1)\n",
        "  conf_matrix = confusion_matrix(Y, y_pred_labels)\n",
        "  print (\"\\nConfusion matrix for the multi-class clasification using linear regression:\")\n",
        "  print (conf_matrix)\n",
        "\n"
      ],
      "metadata": {
        "id": "p7TnIJaAna7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Results**"
      ],
      "metadata": {
        "id": "CoD2WQnzBNC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show results on test set\n",
        "\n",
        "print(\"\\n\\nResults for linear regression:\")\n",
        "show_results_linear_regression(X_train, Y_train_oh, X_test,Y_test_oh)"
      ],
      "metadata": {
        "id": "kBgO3aaGpKDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bfab139-8bb5-4af3-ad5e-a994d3a78818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Results for linear regression:\n",
            "\n",
            "In-Sample Erorr (MSE) for linear regresson: 0.02994\n",
            "ACC for multi-class clasification using linear regression = 85.03%\n",
            "\n",
            "Confusion matrix for the multi-class clasification using linear regression:\n",
            "[[ 904    0    1    2    5    6   10    1   12    2]\n",
            " [   0 1100    4    1    4    5    1    0    8    0]\n",
            " [  17   54  816   29   20    2   28   11   48    7]\n",
            " [   8   22   31  848    2   23   13   19   24   24]\n",
            " [   2   23    9    2  836   10    4    6    8   60]\n",
            " [  26   14    3   82   20  690   30   11   39   28]\n",
            " [  19   12   12    0   18   19  933    0    6    0]\n",
            " [   7   35    5   10   33    1    0  894    1   47]\n",
            " [   9   70   10   46   21   38   11    8  737   31]\n",
            " [  20   12    3   16   70    2    0   79    5  745]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Discussion**"
      ],
      "metadata": {
        "id": "gQ_7ybHEVrKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we compare the results of the multi-class perceptron, linear  regression and softmax regression models for the multi-class classification of the MNIST dataset.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CtEh5JsYKP6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Multi-Class Perceptron:**\n",
        "\n",
        "The multi-class perceptron introduces a unique two-step approach. Initially, 10 binary perceptrons are trained, each specialized in distinguishing one specific digit from the others. The weights learned by these binary perceptrons are then utilized as initial weights for a multi-class perceptron, which integrates this knowledge for the final classification.\n",
        "\n",
        "This approach strikes a balance between simplicity and performance. The multi-class perceptron achieves a competitive accuracy of 88.20% on the training data and 87.94% on the test data. It leverages the feature learning from binary perceptrons effectively, showcasing its ability to capture the essential patterns in the data.\n",
        "\n",
        "However, challenges persist, particularly in distinguishing visually similar digits such as 5, 8, and 9. This indicates areas for potential improvement, and further refinement of the multi-class perceptron, or exploration of alternative architectures, could enhance its performance."
      ],
      "metadata": {
        "id": "1kghGEMDLBco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression:**\n",
        "\n",
        "Linear regression, being a simple and straightforward model, is known for its ease of implementation and interpretation. In the context of our mission, linear regression achieves a respectable accuracy of 85.25%. However, its simplicity comes with limitations, particularly when it comes to capturing the complex relationships inherent in handwritten characters. Linear regression might struggle with the intricate details and variations present in the different digits.\n",
        "\n",
        "In terms of the confusion matrix, we observe challenges in distinguishing visually similar digits, such as 5 and 8. This suggests that linear regression may face difficulties in making subtle distinctions required for accurate digit recognition.\n",
        "\n"
      ],
      "metadata": {
        "id": "eb-lQHslLS_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Softmax Regression:**\n",
        "\n",
        "Softmax regression, designed explicitly for multi-class classification, provides a more probabilistic framework. It models the probabilities of each class and selects the one with the highest probability as the predicted label. In the case of the MNIST dataset, softmax regression achieves the highest overall accuracy of 87.79%. The probabilistic nature of softmax regression allows it to better handle the complexities of distinguishing between visually similar digits.\n",
        "\n",
        "Examining the confusion matrix, softmax regression showcases higher true positive rates across all digits, indicating its effectiveness in capturing the nuances of digit recognition. It excels in scenarios where understanding the certainty of predictions is crucial. This conclusion arises organically from the manner in which the In-Sample Error is computed. In cases where the algorithm predicts an instance as correct, but it is, in fact, incorrect, a substantial error is added to the cumulative sum. Consequently, during gradient descent optimization, there is a tendency for the algorithm to mitigate false positive predictions, given the significant impact these errors have on the overall error calculation.\n",
        "\n"
      ],
      "metadata": {
        "id": "ciRulvt_LtuR"
      }
    }
  ]
}